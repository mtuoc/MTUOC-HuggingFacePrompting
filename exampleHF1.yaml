# --- FILE AND DATA SETTINGS ---
file_settings:
  input_filename: totranslate.txt
  output_filename: translated_hf.txt
  delimiter: '\t' 

# --- HUGGING FACE SETTINGS ---
hf_settings:
  # Examples: "mistralai/Mistral-7B-v0.1", "meta-llama/Llama-2-7b-hf", or local path
  model: "BSC-LT/salamandraTA-7b-instruct"
  
  # --- Generation Parameters ---
  temperature: 0.0      # Lower values are more deterministic. Note: 0.0 uses greedy search.
  max_new_tokens: 128   # How many tokens to generate (similar to num_predict)
  repeat_penalty: 1.2   # Penalty for repeating tokens
  top_k: 40             # Limits vocabulary to top K choices
  top_p: 0.9            # Nucleus sampling

# --- LLM PROMPT AND RESPONSE PARSING ---
prompt_settings:
  prompt_template: |
    Translate the following text from Russian into Catalan.
    Russian: {P[0]} 
    Catalan: 
  regex_pattern: '^(.+?)(?=\\n|\n|$)'
  # '^(.+?)(?=\\n|\n|$)' takes the first line of the answer
  # or None if no regex needed
